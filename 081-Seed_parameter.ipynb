{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeJeonJin/-GPT--AI-/blob/main/081-Seed_parameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZmnHYqqTmypG",
        "outputId": "8de38315-372f-4cb1-f271-7e0584f69764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.70.0\n",
            "    Uninstalling openai-1.70.0:\n",
            "      Successfully uninstalled openai-1.70.0\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai | grep Version"
      ],
      "metadata": {
        "id": "H1iVojDEm7Yh",
        "outputId": "28b30c62-313c-437e-a998-1b4efcb767ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version: 0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-TAk880W1rfdYHX7UzgCnT3El|bkFJXEVFCtHEDILxOw|0aTlb\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "geJ4Fqse4myv",
        "outputId": "96cc7ac1-5c5d-4740-eedf-ece583e0eef3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/.env: line 2: bkFJXEVFCtHEDILxOw: command not found\n",
            "/content/.env: line 2: 0aTlb: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "xmTMw43j4g9a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import openai\n",
        "import pprint\n",
        "import difflib\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "GPT_MODEL = \"gpt-3.5-turbo-1106\""
      ],
      "metadata": {
        "id": "I0ktS_CnnD4t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_chat_response(system_message: str, user_request: str, seed: int = None):\n",
        "    try:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": user_request},\n",
        "        ]\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=GPT_MODEL,\n",
        "            messages=messages,\n",
        "            seed=seed,\n",
        "            max_tokens=200,\n",
        "            temperature=0.7,\n",
        "        )\n",
        "\n",
        "        response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "        system_fingerprint = response[\"system_fingerprint\"]\n",
        "        prompt_tokens = response[\"usage\"][\"prompt_tokens\"]\n",
        "        completion_tokens = (\n",
        "            response[\"usage\"][\"total_tokens\"] - response[\"usage\"][\"prompt_tokens\"]\n",
        "        )\n",
        "\n",
        "        table = f\"\"\"\n",
        "        <table>\n",
        "        <tr><th>Response</th><td>{response_content}</td></tr>\n",
        "        <tr><th>System Fingerprint</th><td>{system_fingerprint}</td></tr>\n",
        "        <tr><th>Number of prompt tokens</th><td>{prompt_tokens}</td></tr>\n",
        "        <tr><th>Number of completion tokens</th><td>{completion_tokens}</td></tr>\n",
        "        </table>\n",
        "        \"\"\"\n",
        "        display(HTML(table))\n",
        "\n",
        "        return response_content\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# This function compares two responses and displays the differences in a table.\n",
        "# Deletions are highlighted in red and additions are highlighted in green.\n",
        "# If no differences are found, it prints \"No differences found.\"\n",
        "\n",
        "\n",
        "def compare_responses(previous_response: str, response: str):\n",
        "    d = difflib.Differ()\n",
        "    diff = d.compare(previous_response.splitlines(), response.splitlines())\n",
        "\n",
        "    diff_table = \"<table>\"\n",
        "    diff_exists = False\n",
        "\n",
        "    for line in diff:\n",
        "        if line.startswith(\"- \"):\n",
        "            diff_table += f\"<tr style='color: red;'><td>{line}</td></tr>\"\n",
        "            diff_exists = True\n",
        "        elif line.startswith(\"+ \"):\n",
        "            diff_table += f\"<tr style='color: green;'><td>{line}</td></tr>\"\n",
        "            diff_exists = True\n",
        "        else:\n",
        "            diff_table += f\"<tr><td>{line}</td></tr>\"\n",
        "\n",
        "    diff_table += \"</table>\"\n",
        "\n",
        "    if diff_exists:\n",
        "        display(HTML(diff_table))\n",
        "    else:\n",
        "        print(\"No differences found.\")"
      ],
      "metadata": {
        "id": "37Uh7LxQnpAx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"고래를 주제\"\n",
        "system_message = \"당신은 훌륭한 소설가이고, 나는 당신 글을 좋아하는 사람입니다.\"\n",
        "user_request = f\"재미난 이야기 3줄 작성 {topic}.\"\n",
        "\n",
        "previous_response = await get_chat_response(\n",
        "    system_message=system_message, user_request=user_request\n",
        ")\n",
        "\n",
        "response = await get_chat_response(\n",
        "    system_message=system_message, user_request=user_request\n",
        ")\n",
        "\n",
        "# The function compare_responses is then called with the two responses as arguments.\n",
        "# This function will compare the two responses and display the differences in a table.\n",
        "# If no differences are found, it will print \"No differences found.\"\n",
        "compare_responses(previous_response, response)"
      ],
      "metadata": {
        "id": "X3Hkthssnsom",
        "outputId": "20031406-6a98-43c2-d7d1-f77dcdcdc789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred: Incorrect API key provided: sk-. You can find your API key at https://platform.openai.com/account/api-keys.\n",
            "An error occurred: Incorrect API key provided: sk-. You can find your API key at https://platform.openai.com/account/api-keys.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'splitlines'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-40c57fc64e7e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# This function will compare the two responses and display the differences in a table.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# If no differences are found, it will print \"No differences found.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mcompare_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-7e7f4f842a93>\u001b[0m in \u001b[0;36mcompare_responses\u001b[0;34m(previous_response, response)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompare_responses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_response\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdifflib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mdiff_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<table>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'splitlines'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 123\n",
        "response = await get_chat_response(\n",
        "    system_message=system_message, seed=SEED, user_request=user_request\n",
        ")\n",
        "previous_response = response\n",
        "response = await get_chat_response(\n",
        "    system_message=system_message, seed=SEED, user_request=user_request\n",
        ")\n",
        "\n",
        "compare_responses(previous_response, response)"
      ],
      "metadata": {
        "id": "q4bn9NAQoOrV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}